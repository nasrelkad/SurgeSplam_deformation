{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Paths:\n",
      "/media/thesis_ssd/code/EndoGSLAM/EndoGSLAM\n",
      "/media/thesis_ssd/anaconda/envs/endogslam/lib/python310.zip\n",
      "/media/thesis_ssd/anaconda/envs/endogslam/lib/python3.10\n",
      "/media/thesis_ssd/anaconda/envs/endogslam/lib/python3.10/lib-dynload\n",
      "\n",
      "/media/thesis_ssd/anaconda/envs/endogslam/lib/python3.10/site-packages\n",
      "/media/thesis_ssd/anaconda/envs/endogslam/lib/python3.10/site-packages/setuptools/_vendor\n",
      "/tmp/tmp9hezfs3y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:dinov2:xFormers not available\n",
      "WARNING:dinov2:xFormers not available\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.slam_helpers import transform_to_frame,transformed_params2depthplussilhouette,transformed_params2rendervar,transformed_GRNparams2rendervar,transformed_GRNparams2depthplussilhouette\n",
    "from diff_gaussian_rasterization import GaussianRasterizer as Renderer\n",
    "from scripts.main_SurgeSplat import deform_gaussians, setup_camera\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "intrinsics = torch.tensor([[199.6883,   0.0000, 166.3290],\n",
    "        [  0.0000, 249.4753, 170.4058],\n",
    "        [  0.0000,   0.0000,   1.0000]], device='cuda:0')\n",
    "w2c = torch.tensor([[ 1.0000e+00,  6.5711e-11,  2.3283e-10,  0.0000e+00],\n",
    "        [-3.1832e-11,  1.0000e+00, -7.4115e-21,  0.0000e+00],\n",
    "        [-9.2644e-22,  2.9104e-11,  1.0000e+00,  0.0000e+00],\n",
    "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0000e+00]], device='cuda:0')\n",
    "\n",
    "cam = setup_camera(336,336, intrinsics.cpu().numpy(), w2c.detach().cpu().numpy(), use_simplification=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = 1\n",
    "params_np = np.load(f'/media/thesis_ssd/code/EndoGSLAM/EndoGSLAM/experiments/EndoNerf cutting_deform_short_simple_20/cutting_deform_short_simple_20/params.npz',allow_pickle=True)\n",
    "params={}\n",
    "for key in params_np.keys():\n",
    "    try:\n",
    "        params[key] = torch.tensor(params_np[key]).cuda()\n",
    "    except:\n",
    "        params[key] = [torch.tensor(params_np[key][i]).cuda() for i in range(params_np[key].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0018, device='cuda:0')\n",
      "torch.Size([112896, 3])\n",
      "tensor(0.0018, device='cuda:0')\n",
      "torch.Size([112896, 3])\n",
      "tensor(0.0073, device='cuda:0')\n",
      "torch.Size([112918, 3])\n",
      "tensor(0.0127, device='cuda:0')\n",
      "torch.Size([112929, 3])\n",
      "tensor(0.0181, device='cuda:0')\n",
      "torch.Size([112943, 3])\n",
      "tensor(0.0235, device='cuda:0')\n",
      "torch.Size([112951, 3])\n",
      "tensor(0.0286, device='cuda:0')\n",
      "torch.Size([112957, 3])\n",
      "tensor(0.0334, device='cuda:0')\n",
      "torch.Size([112962, 3])\n",
      "tensor(0.0334, device='cuda:0')\n",
      "torch.Size([112962, 3])\n",
      "tensor(0.0383, device='cuda:0')\n",
      "torch.Size([112963, 3])\n",
      "tensor(0.0437, device='cuda:0')\n",
      "torch.Size([112969, 3])\n",
      "tensor(0.0491, device='cuda:0')\n",
      "torch.Size([112972, 3])\n",
      "tensor(0.0544, device='cuda:0')\n",
      "torch.Size([112975, 3])\n",
      "tensor(0.0544, device='cuda:0')\n",
      "torch.Size([112975, 3])\n",
      "tensor(0.0544, device='cuda:0')\n",
      "torch.Size([112975, 3])\n",
      "tensor(0.0544, device='cuda:0')\n",
      "torch.Size([112975, 3])\n",
      "tensor(0.0544, device='cuda:0')\n",
      "torch.Size([112975, 3])\n",
      "tensor(0.0544, device='cuda:0')\n",
      "torch.Size([112975, 3])\n",
      "tensor(0.0544, device='cuda:0')\n",
      "torch.Size([112975, 3])\n",
      "tensor(0.0544, device='cuda:0')\n",
      "torch.Size([112975, 3])\n",
      "tensor(0.0588, device='cuda:0')\n",
      "torch.Size([112976, 3])\n",
      "tensor(0.0632, device='cuda:0')\n",
      "torch.Size([112978, 3])\n",
      "tensor(0.0664, device='cuda:0')\n",
      "torch.Size([112980, 3])\n",
      "tensor(0.0715, device='cuda:0')\n",
      "torch.Size([112982, 3])\n",
      "tensor(0.0715, device='cuda:0')\n",
      "torch.Size([112982, 3])\n",
      "tensor(0.0728, device='cuda:0')\n",
      "torch.Size([112984, 3])\n",
      "tensor(0.0778, device='cuda:0')\n",
      "torch.Size([112987, 3])\n",
      "tensor(0.0830, device='cuda:0')\n",
      "torch.Size([112991, 3])\n",
      "tensor(0.0867, device='cuda:0')\n",
      "torch.Size([112992, 3])\n",
      "tensor(0.0867, device='cuda:0')\n",
      "torch.Size([112992, 3])\n",
      "tensor(0.0867, device='cuda:0')\n",
      "torch.Size([112992, 3])\n",
      "tensor(0.0867, device='cuda:0')\n",
      "torch.Size([112992, 3])\n",
      "tensor(0.0867, device='cuda:0')\n",
      "torch.Size([112992, 3])\n",
      "tensor(0.0867, device='cuda:0')\n",
      "torch.Size([112992, 3])\n",
      "tensor(0.0867, device='cuda:0')\n",
      "torch.Size([112992, 3])\n",
      "tensor(0.0867, device='cuda:0')\n",
      "torch.Size([112992, 3])\n",
      "tensor(0.0867, device='cuda:0')\n",
      "torch.Size([112992, 3])\n",
      "tensor(0.0867, device='cuda:0')\n",
      "torch.Size([112992, 3])\n",
      "tensor(0.0903, device='cuda:0')\n",
      "torch.Size([112993, 3])\n",
      "tensor(0.0958, device='cuda:0')\n",
      "torch.Size([112995, 3])\n",
      "tensor(0.0958, device='cuda:0')\n",
      "torch.Size([112995, 3])\n",
      "tensor(0.0989, device='cuda:0')\n",
      "torch.Size([112997, 3])\n",
      "tensor(0.0945, device='cuda:0')\n",
      "torch.Size([112999, 3])\n",
      "tensor(0.0994, device='cuda:0')\n",
      "torch.Size([113000, 3])\n",
      "tensor(0.1047, device='cuda:0')\n",
      "torch.Size([113005, 3])\n",
      "tensor(0.1044, device='cuda:0')\n",
      "torch.Size([113006, 3])\n",
      "tensor(0.1076, device='cuda:0')\n",
      "torch.Size([113011, 3])\n",
      "tensor(0.1095, device='cuda:0')\n",
      "torch.Size([113018, 3])\n",
      "tensor(0.1095, device='cuda:0')\n",
      "torch.Size([113018, 3])\n",
      "tensor(0.1147, device='cuda:0')\n",
      "torch.Size([113020, 3])\n",
      "tensor(0.1197, device='cuda:0')\n",
      "torch.Size([113024, 3])\n"
     ]
    }
   ],
   "source": [
    "def deform_gaussians(params, time, deform_grad, N=5,deformation_type = 'gaussian'):\n",
    "    \"\"\"\n",
    "    Calculate deformations using the N closest basis functions based on |time - bias|.\n",
    "\n",
    "    Args:\n",
    "        params (dict): Dictionary containing deformation parameters.\n",
    "        time (torch.Tensor): Current time step.\n",
    "        deform_grad (bool): Whether to calculate gradients for deformations.\n",
    "        N (int): Number of closest basis functions to consider.\n",
    "\n",
    "    Returns:\n",
    "        xyz (torch.Tensor): Updated 3D positions.\n",
    "        rots (torch.Tensor): Updated rotations.\n",
    "        scales (torch.Tensor): Updated scales.\n",
    "    \"\"\"\n",
    "    if deformation_type =='gaussian':\n",
    "        if True:\n",
    "            if deform_grad:\n",
    "                weights = params['deform_weights']\n",
    "                stds = params['deform_stds']\n",
    "                biases = params['deform_biases']\n",
    "            else:\n",
    "                weights = params['deform_weights'].detach()\n",
    "                stds = params['deform_stds'].detach()\n",
    "                biases = params['deform_biases'].detach()\n",
    "\n",
    "            # Calculate the absolute difference between time and biases\n",
    "            time_diff = torch.abs(time - biases)\n",
    "\n",
    "            # Get the indices of the N smallest time differences\n",
    "            _, top_indices = torch.topk(-time_diff, N, dim=1)  # Negative for smallest values\n",
    "\n",
    "            # Create a mask to select only the top N basis functions\n",
    "            mask = torch.zeros_like(time_diff, dtype=torch.float)\n",
    "            mask.scatter_(1, top_indices, 1.0)\n",
    "\n",
    "            # Apply the mask to weights and biases\n",
    "            masked_weights = weights * mask\n",
    "            masked_biases = biases * mask\n",
    "\n",
    "            # Calculate deformations\n",
    "            deform = torch.sum(\n",
    "                masked_weights * torch.exp(-1 / (2 * stds**2) * (time - masked_biases)**2), dim=1\n",
    "            )  # Nx10 gaussians deformations\n",
    "\n",
    "            deform_xyz = deform[:, :3]\n",
    "            deform_rots = deform[:, 3:7]\n",
    "            deform_scales = deform[:, 7:10]\n",
    "        else:\n",
    "            if deform_grad:\n",
    "                weights = params['deform_weights']\n",
    "                stds = params['deform_stds']\n",
    "                biases = params['deform_biases']\n",
    "            else:\n",
    "                weights = params['deform_weights'].detach()\n",
    "                stds = params['deform_stds'].detach()\n",
    "                biases = params['deform_biases'].detach()\n",
    "\n",
    "            # Calculate the absolute difference between time and biases\n",
    "            time_diff = torch.abs(time - biases)\n",
    "\n",
    "            # Get the indices of the N smallest time differences\n",
    "            _, top_indices = torch.topk(-time_diff, N, dim=1)  # Negative for smallest values\n",
    "\n",
    "            # Create a mask to select only the top N basis functions\n",
    "            mask = torch.zeros_like(time_diff, dtype=torch.float)\n",
    "            mask.scatter_(1, top_indices, 1.0).detach()\n",
    "\n",
    "            # Register a gradient hook to zero out gradients for irrelevant basis functions\n",
    "            if deform_grad:\n",
    "                def zero_out_irrelevant_gradients(grad):\n",
    "                    return grad * mask\n",
    "\n",
    "                weights.register_hook(zero_out_irrelevant_gradients)\n",
    "                biases.register_hook(zero_out_irrelevant_gradients)\n",
    "                stds.register_hook(zero_out_irrelevant_gradients)\n",
    "\n",
    "            # Calculate deformations\n",
    "            deform = torch.sum(\n",
    "                weights * torch.exp(-1 / (2 * stds**2) * (time - biases)**2), dim=1\n",
    "            )  # Nx10 gaussians deformations\n",
    "\n",
    "            deform_xyz = deform[:, :3]\n",
    "            deform_rots = deform[:, 3:7]\n",
    "            deform_scales = deform[:, 7:10]\n",
    "\n",
    "        xyz = params['means3D'] + deform_xyz\n",
    "        rots = params['unnorm_rotations'] + deform_rots\n",
    "        scales = params['log_scales'] + deform_scales\n",
    "        opacities = params['logit_opacities']\n",
    "        colors = params['rgb_colors']\n",
    "\n",
    "\n",
    "    elif deformation_type == 'simple':\n",
    "        # with torch.no_grad():\n",
    "        xyz = params['means3D'][time]\n",
    "        rots = params['unnorm_rotations'][time]\n",
    "        scales = params['log_scales'][time]\n",
    "        opacities = params['logit_opacities'][time]\n",
    "        colors = params['rgb_colors'][time]\n",
    "\n",
    "    return xyz, rots, scales,opacities, colors\n",
    "for i in range(params['cam_trans'].shape[-1]):\n",
    "    params['cam_trans'][...,i][...,-1] += 0\n",
    "\n",
    "for id in range(params['cam_unnorm_rots'].shape[-1]):\n",
    "    local_means,local_rots,local_scales,local_opacities,local_colors = deform_gaussians(params,id,deform_grad = True,deformation_type='simple')\n",
    "\n",
    "\n",
    "    #  print(torch.sum(local_means-params['means3D']))\n",
    "\n",
    "    transformed_pts = transform_to_frame(local_means,params,id,False,False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize Render Variables\n",
    "    rendervar = transformed_GRNparams2rendervar(params, transformed_pts,local_rots,local_scales,local_opacities,local_colors)\n",
    "    print(local_scales.max())\n",
    "    rv_store = {}\n",
    "    for key in rendervar.keys():\n",
    "        rv_store[key] = rendervar[key].cpu().detach()\n",
    "        local_means_store = local_means.cpu()\n",
    "        local_scales_store = local_rots.cpu()\n",
    "        local_rots_store = local_rots.cpu()\n",
    "        transformed_pts_store = transformed_pts.cpu()\n",
    "\n",
    "\n",
    "\n",
    "    #  rendervar['means3D'].retain_grad()\n",
    "\n",
    "    depth_sil_rendervar = transformed_params2depthplussilhouette(params, w2c,\n",
    "                                            transformed_pts,local_rots,local_scales,local_opacities)\n",
    "\n",
    "\n",
    "    #RGB Rendering\n",
    "\n",
    "    rendervar['means2D'].retain_grad()\n",
    "    im, radius, _ = Renderer(raster_settings=cam)(**rendervar)\n",
    "    # variables['means2D'] = rendervar['means2D'] # Gradient only accum from colour render for densification\n",
    "    img = Image.fromarray((im.permute(1,2,0).cpu().detach().numpy()*255).astype(np.uint8))\n",
    "    os.makedirs(f'./eval_plots/plots_simple/',exist_ok=True)\n",
    "    img.save(f'./eval_plots/plots_simple/{id}.png')\n",
    "\n",
    "    print(local_means.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 51])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['cam_trans'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# weights =   params['deform_weights'].cpu().detach()\n",
    "# biases =    params['deform_biases'].cpu().detach()\n",
    "# stds =      params['deform_stds'].cpu().detach()\n",
    "\n",
    "# deforms = []\n",
    "# deformsx1 = []\n",
    "# for time in range(100):\n",
    "#     deform = torch.sum(weights*torch.exp(-1/(2*stds**2)*(time-biases)**2),1)\n",
    "#     deforms.append(deform) # Nx10 gaussians deformations\n",
    "#     deformsx1.append(deform[0,0])\n",
    "# fig,ax = plt.subplots(10,10,figsize = (25,25),sharey=True)\n",
    "# for i in range(10):\n",
    "#     for ii in range(10):\n",
    "#         ax[ii,i].plot([deforms[idx][i+91720//3,ii] for idx in range(len(deforms))])\n",
    "#         ax[ii,i].axhline(y = 0.0,color = 'r', linestyle = '--')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from GRN.models.conv_unet import GaussianRegressionNetwork\n",
    "# import torch\n",
    "\n",
    "# state_dict = torch.load('logs/GRN_6/checkpoint.pth',weights_only=False)\n",
    "# model_state_dict = state_dict['model']\n",
    "\n",
    "# model = GaussianRegressionNetwork()\n",
    "# # model.load_state_dict(model_state_dict)\n",
    "\n",
    "# torch.save(model.state_dict(),'GRN/models/GRN_v1.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {}\n",
    "a['hoi']=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "endogslam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
